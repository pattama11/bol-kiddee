{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8361705,"sourceType":"datasetVersion","datasetId":4969544}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plan & Recommendation","metadata":{}},{"cell_type":"code","source":"#ปรับpromt\n#tagชื่อ\n#translate\n#มองดูว่าคำถามตรงไหนmatchกัน\n#ใช้pattern แยกคำถามด้วยrule baseก่อน","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:07.677348Z","iopub.execute_input":"2024-05-09T15:35:07.677742Z","iopub.status.idle":"2024-05-09T15:35:07.682866Z","shell.execute_reply.started":"2024-05-09T15:35:07.677707Z","shell.execute_reply":"2024-05-09T15:35:07.681743Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\nfrom transformers import AutoModelForSequenceClassification\nimport ast\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.autograd as autograd         # computation graph\nfrom torch import Tensor                  # tensor node in the computation graph\nimport torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\nfrom torch.jit import script, trace       # hybrid frontend decorator and tracing jit\nfrom sklearn.metrics import f1_score\nfrom datetime import datetime\nimport random\nimport time\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup, TFXLMRobertaModel,  XLMRobertaForSequenceClassification\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:08.228655Z","iopub.execute_input":"2024-05-09T15:35:08.229382Z","iopub.status.idle":"2024-05-09T15:35:15.565337Z","shell.execute_reply.started":"2024-05-09T15:35:08.229350Z","shell.execute_reply":"2024-05-09T15:35:15.564519Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-09 15:35:13.108344: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-09 15:35:13.108400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-09 15:35:13.109895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:15.567228Z","iopub.execute_input":"2024-05-09T15:35:15.567782Z","iopub.status.idle":"2024-05-09T15:35:15.599055Z","shell.execute_reply.started":"2024-05-09T15:35:15.567752Z","shell.execute_reply":"2024-05-09T15:35:15.598087Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:15.601328Z","iopub.execute_input":"2024-05-09T15:35:15.602020Z","iopub.status.idle":"2024-05-09T15:35:15.605946Z","shell.execute_reply.started":"2024-05-09T15:35:15.601989Z","shell.execute_reply":"2024-05-09T15:35:15.605022Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install transformers ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:15.608610Z","iopub.execute_input":"2024-05-09T15:35:15.609729Z","iopub.status.idle":"2024-05-09T15:35:28.454529Z","shell.execute_reply.started":"2024-05-09T15:35:15.609699Z","shell.execute_reply":"2024-05-09T15:35:28.453302Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers[tf-cpu]","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:35:28.456000Z","iopub.execute_input":"2024-05-09T15:35:28.456331Z","iopub.status.idle":"2024-05-09T15:35:41.457359Z","shell.execute_reply.started":"2024-05-09T15:35:28.456299Z","shell.execute_reply":"2024-05-09T15:35:41.456362Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[tf-cpu] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (4.66.1)\nRequirement already satisfied: tensorflow-cpu<2.16,>=2.6 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (2.15.1)\nRequirement already satisfied: onnxconverter-common in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (1.13.0)\nRequirement already satisfied: tf2onnx in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (1.16.1)\nRequirement already satisfied: tensorflow-text<2.16 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (2.15.0)\nRequirement already satisfied: keras-nlp>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[tf-cpu]) (0.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[tf-cpu]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[tf-cpu]) (4.9.0)\nRequirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (from keras-nlp>=0.3.1->transformers[tf-cpu]) (0.1.7)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-nlp>=0.3.1->transformers[tf-cpu]) (1.4.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-nlp>=0.3.1->transformers[tf-cpu]) (13.7.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-nlp>=0.3.1->transformers[tf-cpu]) (0.1.8)\nRequirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-nlp>=0.3.1->transformers[tf-cpu]) (0.2.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[tf-cpu]) (3.1.1)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.15.0)\nRequirement already satisfied: tensorflow-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text<2.16->transformers[tf-cpu]) (0.16.1)\nRequirement already satisfied: tensorflow<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text<2.16->transformers[tf-cpu]) (2.15.1)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from onnxconverter-common->transformers[tf-cpu]) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[tf-cpu]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[tf-cpu]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[tf-cpu]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[tf-cpu]) (2024.2.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.0.2)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub>=0.13.0->tensorflow-text<2.16->transformers[tf-cpu]) (2.15.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-nlp>=0.3.1->transformers[tf-cpu]) (0.0.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp>=0.3.1->transformers[tf-cpu]) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp>=0.3.1->transformers[tf-cpu]) (2.17.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.3.1->transformers[tf-cpu]) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu<2.16,>=2.6->transformers[tf-cpu]) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pythainlp -q","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:09.643253Z","iopub.execute_input":"2024-05-09T15:36:09.643650Z","iopub.status.idle":"2024-05-09T15:36:22.023368Z","shell.execute_reply.started":"2024-05-09T15:36:09.643616Z","shell.execute_reply":"2024-05-09T15:36:22.021881Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForSequenceClassification, \n    AutoTokenizer, \n\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.025610Z","iopub.execute_input":"2024-05-09T15:36:22.025999Z","iopub.status.idle":"2024-05-09T15:36:22.031271Z","shell.execute_reply.started":"2024-05-09T15:36:22.025965Z","shell.execute_reply":"2024-05-09T15:36:22.030141Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/super-train-title/super_train_title.csv', index_col = 0)\n#test_df = pd.read_csv('test_add_tag.csv', index_col = 0)\n# pat_df = pd.read_csv('/kaggle/input/legal-act-classification/patterns.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.032709Z","iopub.execute_input":"2024-05-09T15:36:22.033107Z","iopub.status.idle":"2024-05-09T15:36:22.087376Z","shell.execute_reply.started":"2024-05-09T15:36:22.033070Z","shell.execute_reply":"2024-05-09T15:36:22.086622Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"prompts = []\nfor index, row in train_df.iterrows():\n    prompt = f'''\n    คุณเป็นผู้ช่วยทางด้านนิติกรรม คุณจะต้องตอบคำถามทางด้านนิติกรรมโดยใช้ข้อมูลต้นฉบับเท่านั้น\\n\n    ข้อมูลต้นฉบับ : {row['context']} \\n\n    คำถาม : คุณ {row['question']} จะทำการ {row['legal_act']} ทำได้หรือไม่? ตอบแค่ได้ หรือ ไม่ได้ ถ้าได้ให้ตอบ 1 และถ้าไม่ได้ให้ตอบ 0'''\n    prompts.append(prompt)\n\n# Create a new column named 'prompt' with the generated prompts\ntrain_df['prompt'] = prompts\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.089503Z","iopub.execute_input":"2024-05-09T15:36:22.089845Z","iopub.status.idle":"2024-05-09T15:36:22.409357Z","shell.execute_reply.started":"2024-05-09T15:36:22.089818Z","shell.execute_reply":"2024-05-09T15:36:22.408534Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"/kaggle/working/fortranslate.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:50:51.848312Z","iopub.execute_input":"2024-05-09T15:50:51.848838Z","iopub.status.idle":"2024-05-09T15:50:52.021873Z","shell.execute_reply.started":"2024-05-09T15:50:51.848799Z","shell.execute_reply":"2024-05-09T15:50:52.020863Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"len(prompts)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:46:55.908598Z","iopub.execute_input":"2024-05-09T15:46:55.909444Z","iopub.status.idle":"2024-05-09T15:46:55.915928Z","shell.execute_reply.started":"2024-05-09T15:46:55.909407Z","shell.execute_reply":"2024-05-09T15:46:55.914890Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"4429"},"metadata":{}}]},{"cell_type":"code","source":"train_df.keys()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-09T15:36:22.418213Z","iopub.execute_input":"2024-05-09T15:36:22.418501Z","iopub.status.idle":"2024-05-09T15:36:22.427935Z","shell.execute_reply.started":"2024-05-09T15:36:22.418476Z","shell.execute_reply":"2024-05-09T15:36:22.426841Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'rgno', 'context', 'pattern', 'question', 'legal_act',\n       'condition', 'answer', 'prompt'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"#train_df = train_df.drop(columns=['prompt'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.429227Z","iopub.execute_input":"2024-05-09T15:36:22.429597Z","iopub.status.idle":"2024-05-09T15:36:22.435256Z","shell.execute_reply.started":"2024-05-09T15:36:22.429550Z","shell.execute_reply":"2024-05-09T15:36:22.434416Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#data split\n\nX = train_df['prompt']  # Your features\ny = train_df['answer']  # Your target labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#convert into PyTorch Datasets\n#train_data = TensorDataset(X_train,y_train)\n\n#translate into dataloader objects\n#batchsize    = 8\n#train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n\n#print(f\"Training set size: {len(train_data)}\")\n\n#print(f\"Validation set shape: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.436561Z","iopub.execute_input":"2024-05-09T15:36:22.436934Z","iopub.status.idle":"2024-05-09T15:36:22.446760Z","shell.execute_reply.started":"2024-05-09T15:36:22.436900Z","shell.execute_reply":"2024-05-09T15:36:22.445976Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#load model\nmodels = [\n    AutoModelForSequenceClassification.from_pretrained(\n        \"airesearch/wangchanberta-base-att-spm-uncased\",\n        #num_labels=2,  # Assuming binary classification\n        #hidden_dropout_prob=0.2 \n    ),\n    #AutoModelForSequenceClassification.from_pretrained(\n    AutoModelForSequenceClassification.from_pretrained(\n        'FacebookAI/xlm-roberta-base'#,\n        #hidden_size=512,  # Example: customize hidden size\n        #num_attention_heads=8\n    ),]\n\n#choose tokenize\ntokenizers = [\n    AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\"), \n    AutoTokenizer.from_pretrained('FacebookAI/xlm-roberta-base',  problem_type=\"multi_label_classification\"),\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:22.447868Z","iopub.execute_input":"2024-05-09T15:36:22.448189Z","iopub.status.idle":"2024-05-09T15:36:25.484208Z","shell.execute_reply.started":"2024-05-09T15:36:22.448164Z","shell.execute_reply":"2024-05-09T15:36:25.483370Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model =  AutoModelForSequenceClassification.from_pretrained('FacebookAI/xlm-roberta-base')\ntokenizer = AutoTokenizer.from_pretrained('FacebookAI/xlm-roberta-base',  problem_type=\"multi_label_classification\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:25.487254Z","iopub.execute_input":"2024-05-09T15:36:25.487974Z","iopub.status.idle":"2024-05-09T15:36:27.625221Z","shell.execute_reply.started":"2024-05-09T15:36:25.487935Z","shell.execute_reply":"2024-05-09T15:36:27.624355Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train.review = df_train.str.lower()\nsentences = train_df.prompt.values\n\n# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\nsentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\nlabels = train_df.answer.values","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:31.569218Z","iopub.execute_input":"2024-05-09T15:36:31.569976Z","iopub.status.idle":"2024-05-09T15:36:31.577935Z","shell.execute_reply.started":"2024-05-09T15:36:31.569941Z","shell.execute_reply":"2024-05-09T15:36:31.576920Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\nprint (\"Tokenize the first sentence:\")\nprint (tokenized_texts[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:33.057216Z","iopub.execute_input":"2024-05-09T15:36:33.057608Z","iopub.status.idle":"2024-05-09T15:36:34.951650Z","shell.execute_reply.started":"2024-05-09T15:36:33.057558Z","shell.execute_reply":"2024-05-09T15:36:34.950735Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Tokenize the first sentence:\n['▁[', 'C', 'LS', ']', '▁คุณ', 'เป็น', 'ผู้ช่วย', 'ทางด้าน', 'นิติ', 'กรรม', '▁คุณ', 'จะต้อง', 'ตอบ', 'คําถาม', 'ทางด้าน', 'นิติ', 'กรรม', 'โดยใช้', 'ข้อมูล', 'ต้น', 'ฉบับ', 'เท่านั้น', '▁ข้อมูล', 'ต้น', 'ฉบับ', '▁:', '▁', 'กรรม', 'การ', 'คน', 'ใด', 'คนหนึ่ง', 'ลง', 'ลาย', 'มือ', 'ชื่อ', 'ร่วมกับ', 'กรรม', 'การ', 'อื่น', 'อีกหนึ่ง', 'คน', 'รวม', 'เป็น', 'สอง', 'คน', 'และ', 'ประ', 'ทับ', 'ตรา', 'สําคัญ', 'ของ', 'บริษัท', '▁', 'คําถาม', '▁:', '▁คุณ', '▁[', \"'\", 'P', '000', '6', \"'\", ']', '▁จะ', 'ทําการ', '▁', 'การทํา', 'นิติ', 'กรรม', '▁สํานักงาน', 'ตรวจ', 'คน', 'เข้า', 'เมือง', '▁', 'ทําได้', 'หรือไม่', '?', '▁', 'ตอบ', 'แค่', 'ได้', '▁หรือ', '▁', 'ไม่ได้', '▁ถ้า', 'ได้', 'ให้', 'ตอบ', '▁1', '▁และ', 'ถ้า', 'ไม่ได้', 'ให้', 'ตอบ', '▁0', '▁[', 'S', 'EP', ']']\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = tokenizers[1]\nmodel = models[1]\ninputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n\nwith torch.no_grad():\n    logits = model(**inputs).logits\n\npredicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]\n\n# To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\nnum_labels = len(model.config.id2label)\n\n\nlabels = torch.sum(\n    torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n).to(torch.float)\nloss = model(**inputs, labels=labels).loss","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom tqdm import  tqdm_notebook\n#uncomment all three lines below to convert to ids\ninput_ids=[]\nfor i in tqdm_notebook(range(len(tokenized_texts))):\n  input_ids.append(tokenizer.convert_tokens_to_ids(tokenized_texts[i]))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:35.217293Z","iopub.execute_input":"2024-05-09T15:36:35.217936Z","iopub.status.idle":"2024-05-09T15:36:35.733477Z","shell.execute_reply.started":"2024-05-09T15:36:35.217904Z","shell.execute_reply":"2024-05-09T15:36:35.732494Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_94/1317061965.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  for i in tqdm_notebook(range(len(tokenized_texts))):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4429 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"953f6251c5a1490b8fe89d8fc6f065d5"}},"metadata":{}}]},{"cell_type":"code","source":"labels","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nMAX_LEN = 256\ninput_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:39.420166Z","iopub.execute_input":"2024-05-09T15:36:39.420799Z","iopub.status.idle":"2024-05-09T15:36:39.501395Z","shell.execute_reply.started":"2024-05-09T15:36:39.420767Z","shell.execute_reply":"2024-05-09T15:36:39.500638Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Create attention masks\nattention_masks = []\n# Create a mask of 1s for each token followed by 0s for padding\nfor seq in input_ids:\n  seq_mask = [float(i>0) for i in seq]\n  attention_masks.append(seq_mask)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:41.450168Z","iopub.execute_input":"2024-05-09T15:36:41.450882Z","iopub.status.idle":"2024-05-09T15:36:42.219706Z","shell.execute_reply.started":"2024-05-09T15:36:41.450849Z","shell.execute_reply":"2024-05-09T15:36:42.218874Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Use train_test_split to split our data into train and validation sets for training\n\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,random_state=56, test_size=0.2)\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,random_state=56, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:43.934378Z","iopub.execute_input":"2024-05-09T15:36:43.934774Z","iopub.status.idle":"2024-05-09T15:36:43.947708Z","shell.execute_reply.started":"2024-05-09T15:36:43.934740Z","shell.execute_reply":"2024-05-09T15:36:43.946653Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#Convert all of our data into torch tensors, the required datatype for our model\n\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:45.753787Z","iopub.execute_input":"2024-05-09T15:36:45.754189Z","iopub.status.idle":"2024-05-09T15:36:46.090855Z","shell.execute_reply.started":"2024-05-09T15:36:45.754147Z","shell.execute_reply":"2024-05-09T15:36:46.090015Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 16\n\n# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n# with an iterator the entire dataset does not need to be loaded into memory\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:47.797298Z","iopub.execute_input":"2024-05-09T15:36:47.797702Z","iopub.status.idle":"2024-05-09T15:36:47.804526Z","shell.execute_reply.started":"2024-05-09T15:36:47.797668Z","shell.execute_reply":"2024-05-09T15:36:47.803585Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"## Define model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:49.987257Z","iopub.execute_input":"2024-05-09T15:36:49.988290Z","iopub.status.idle":"2024-05-09T15:36:50.049624Z","shell.execute_reply.started":"2024-05-09T15:36:49.988252Z","shell.execute_reply":"2024-05-09T15:36:50.048591Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"!pip install pytorch_transformers\nfrom pytorch_transformers import *","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:36:51.641280Z","iopub.execute_input":"2024-05-09T15:36:51.641922Z","iopub.status.idle":"2024-05-09T15:37:10.819948Z","shell.execute_reply.started":"2024-05-09T15:36:51.641887Z","shell.execute_reply":"2024-05-09T15:37:10.819102Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting pytorch_transformers\n  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (1.26.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (4.66.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (2023.12.25)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from pytorch_transformers) (0.2.0)\nCollecting sacremoses (from pytorch_transformers)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_transformers) (2024.2.0)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch_transformers)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_transformers) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_transformers) (0.6.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_transformers) (2024.2.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->pytorch_transformers) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->pytorch_transformers) (1.4.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch_transformers) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->pytorch_transformers) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->pytorch_transformers) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch_transformers) (1.16.0)\nDownloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses, botocore, pytorch_transformers\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.69\n    Uninstalling botocore-1.34.69:\n      Successfully uninstalled botocore-1.34.69\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.165 pytorch_transformers-1.2.0 sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torch_optimizer\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:37:10.821654Z","iopub.execute_input":"2024-05-09T15:37:10.821967Z","iopub.status.idle":"2024-05-09T15:37:24.053009Z","shell.execute_reply.started":"2024-05-09T15:37:10.821941Z","shell.execute_reply":"2024-05-09T15:37:24.051845Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting torch_optimizer\n  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m943.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from torch_optimizer) (2.1.2)\nCollecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\nDownloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\nInstalling collected packages: pytorch-ranger, torch_optimizer\nSuccessfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup \nfrom torch_optimizer import RAdam # Install via: pip install torch_optimizer\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:37:24.054543Z","iopub.execute_input":"2024-05-09T15:37:24.054919Z","iopub.status.idle":"2024-05-09T15:37:24.074388Z","shell.execute_reply.started":"2024-05-09T15:37:24.054887Z","shell.execute_reply":"2024-05-09T15:37:24.073636Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"lr = 2e-5\nmax_grad_norm = 1.0\nnum_total_steps = 1000\nnum_warmup_steps = 100\nwarmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n\n\n### In PyTorch-Transformers, optimizer and schedules are splitted and instantiated like this:\noptimizer = RAdam(model.parameters(), lr=lr) \nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:37:24.076465Z","iopub.execute_input":"2024-05-09T15:37:24.076910Z","iopub.status.idle":"2024-05-09T15:37:24.084456Z","shell.execute_reply.started":"2024-05-09T15:37:24.076881Z","shell.execute_reply":"2024-05-09T15:37:24.083479Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:37:24.086051Z","iopub.execute_input":"2024-05-09T15:37:24.086436Z","iopub.status.idle":"2024-05-09T15:37:24.097382Z","shell.execute_reply.started":"2024-05-09T15:37:24.086396Z","shell.execute_reply":"2024-05-09T15:37:24.096389Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"222"},"metadata":{}}]},{"cell_type":"code","source":"model.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:39:03.264281Z","iopub.execute_input":"2024-05-09T15:39:03.264985Z","iopub.status.idle":"2024-05-09T15:39:03.579545Z","shell.execute_reply.started":"2024-05-09T15:39:03.264948Z","shell.execute_reply":"2024-05-09T15:39:03.578557Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"XLMRobertaForSequenceClassification(\n  (roberta): XLMRobertaModel(\n    (embeddings): XLMRobertaEmbeddings(\n      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): XLMRobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x XLMRobertaLayer(\n          (attention): XLMRobertaAttention(\n            (self): XLMRobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): XLMRobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): XLMRobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): XLMRobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): XLMRobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"total_step = len(train_dataloader)\n\n# Store our loss and accuracy for plotting\ntrain_loss_set = []\n\n\nepochs = 2\n\n# trange is a tqdm wrapper around the normal python range\nfor epoch in tqdm_notebook(range(epochs)):\n\n\n\n    # Training\n    # Set our model to training mode (as opposed to evaluation mode)\n    model.train()\n\n    # Tracking variables\n    tr_loss = 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n\n    # Train the data for one epoch\n    for i, batch in enumerate(train_dataloader):\n      # Add batch to GPU\n      batch = tuple(t.to(device) for t in batch)\n      # Unpack the inputs from our dataloader\n      b_input_ids, b_input_mask, b_labels = batch\n      # Forward pass\n      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n      loss = outputs[0]\n      train_loss_set.append(loss.item())\n      # Backward pass\n      loss.backward()\n      # Update parameters and take a step using the computed gradient\n      optimizer.step()\n      scheduler.step()\n      optimizer.zero_grad()\n      if (i) % 50 == 0:\n        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                   .format(epoch+1, epochs, i+1, total_step, loss.item()))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:39:06.441935Z","iopub.execute_input":"2024-05-09T15:39:06.442352Z","iopub.status.idle":"2024-05-09T15:44:40.354704Z","shell.execute_reply.started":"2024-05-09T15:39:06.442315Z","shell.execute_reply":"2024-05-09T15:44:40.353753Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_94/2779366120.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  for epoch in tqdm_notebook(range(epochs)):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"335d966455554e45bfe8725c08996a36"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/2], Step [1/222], Loss: 0.7526\nEpoch [1/2], Step [51/222], Loss: 0.6981\nEpoch [1/2], Step [101/222], Loss: 0.5608\nEpoch [1/2], Step [151/222], Loss: 0.6486\nEpoch [1/2], Step [201/222], Loss: 0.5211\nEpoch [2/2], Step [1/222], Loss: 0.6499\nEpoch [2/2], Step [51/222], Loss: 0.6817\nEpoch [2/2], Step [101/222], Loss: 0.4643\nEpoch [2/2], Step [151/222], Loss: 0.4242\nEpoch [2/2], Step [201/222], Loss: 0.2265\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, \"kuymodel\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:55:25.984958Z","iopub.execute_input":"2024-05-09T15:55:25.985850Z","iopub.status.idle":"2024-05-09T15:55:28.025971Z","shell.execute_reply.started":"2024-05-09T15:55:25.985808Z","shell.execute_reply":"2024-05-09T15:55:28.024885Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"total_step = len(train_dataloader)\n\n# Store our loss and accuracy for plotting\ntrain_loss_set = []\n\n\nepochs = 2\n\n# trange is a tqdm wrapper around the normal python range\nfor epoch in tqdm_notebook(range(epochs)):\n\n\n\n    # Training\n    # Set our model to training mode (as opposed to evaluation mode)\n    model.train()\n\n    # Tracking variables\n    tr_loss = 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n\n    # Train the data for one epoch\n    for i, batch in enumerate(train_dataloader):\n      # Add batch to GPU\n      batch = tuple(t.to(device) for t in batch)\n      # Unpack the inputs from our dataloader\n      b_input_ids, b_input_mask, b_labels = batch\n      # Forward pass\n      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n      loss = outputs[0]\n      train_loss_set.append(loss.item())\n      # Backward pass\n      loss.backward()\n      # Update parameters and take a step using the computed gradient\n      optimizer.step()\n      scheduler.step()\n      optimizer.zero_grad()\n      if (i) % 50 == 0:\n        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n                   .format(epoch+1, epochs, i+1, total_step, loss.item()))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer()\nsvm_model = SVC(kernel='linear')  ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Extraction (for SVM)\nX_train_svm = tfidf_vectorizer.fit_transform(X_train)\nX_test_svm = tfidf_vectorizer.transform(X_test)\n\n# Train SVM\nsvm_model.fit(X_train_svm, y_train)\n\n# Evaluate SVM\nsvm_predictions = svm_model.predict(X_test_svm)\nsvm_f1_macro = f1_score(y_test, svm_predictions, average='macro')  # F1-score (macro average)\nprint(f\"SVM F1-Macro: {svm_f1_macro}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFXLMRobertaForMaskedLM\nimport tensorflow as tf\n\n# Load the XLM-RoBERTa model\nmodel = models[1]\ntokenizer = tokenizers[1]  # Assuming you want to use the tokenizer corresponding to the XLM-RoBERTa model\n\n# Tokenize the input text\ntext = \"The capital of France is <mask>.\"\ninputs = tokenizer(text, return_tensors=\"tf\")\nprint(type(inputs))\n#print(tokenizer)\n#print(inputs[0])\n\n# Get the logits from the XLM-RoBERTa model\nlogits = model(inputs)[0]  # Output of the XLM-RoBERTa model\n\n# Retrieve the index of the masked token\nmask_token_index = tf.where(tf.equal(inputs[\"input_ids\"], tokenizer.mask_token_id))\n\n# Extract the logits corresponding to the masked token\nselected_logits = tf.gather_nd(logits, mask_token_index)\n\n# Get the predicted token ID\npredicted_token_id = tf.math.argmax(selected_logits, axis=-1)\n\n# Decode the predicted token ID\npredicted_token = tokenizer.decode(predicted_token_id)\nprint(predicted_token)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensemble Prediction Function\ndef predict_ensemble(models, tokenizers, svm_model, X, for_svm=False):\n  predictions = []\n\n  for text in X:\n    transformer_preds = []  \n    for model, tokenizer in zip(models, tokenizers):\n      inputs = tokenizer(text, return_tensors=\"tf\")\n      print(inputs)\n    \n      # Assuming your models have a .predict() method for raw predictions\n      model_preds = model(inputs).argmax(axis=-1)[0] \n      transformer_preds.append(model_preds)  \n\n    svm_input = preprocess_text(text, None, for_svm=True)\n    svm_pred = svm_model.predict(svm_input)[0]  # Get class prediction\n\n    # Implement your ensemble logic (e.g., majority voting)\n    if sum(transformer_preds) > len(transformer_preds) / 2 and svm_pred == 1: \n      ensemble_prediction = 1\n    else:\n      ensemble_prediction = 0\n\n    predictions.append(ensemble_prediction)\n\n  return predictions \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction on Test Set\nensemble_predictions = predict_ensemble(models, tokenizers, svm_model, X_test.tolist(), for_svm=True)\n\n# Evaluation using F1-score\nf1_macro = f1_score(y_test, ensemble_predictions, average='macro')\nprint(f\"Ensemble F1-Macro: {f1_macro}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}